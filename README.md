# Safety-Gear-Detection
The project aims to detect whether the person is wearing the gear that ensures safety in factories and construction sites.Using the Tensorflow Object Detection API the model has been extensively trained using a Single Shot Multibox Detector framework and have achieved an accuracy over 98%.

![](https://github.com/sarthakking5/Safety-Gear-Detection/blob/4da7d2544711652d922bd10509c3986012491610/images/output_gif.gif)

# Steps

# 1.Cloning the model

You can install the TensorFlow Object Detection API either with Python Package Installer (pip) or Docker, an open-source platform for deploying and managing containerized applications. For running the Tensorflow Object Detection API locally, Docker is recommended. If you aren't familiar with Docker though, it might be easier to install it using pip.

First clone the master branch of the Tensorflow Models repository:

https://github.com/tensorflow/models.git

# 2.Protobuf Installation/Compilation

The Tensorflow Object Detection API uses Protobufs to configure model and training parameters. Before the framework can be used, the Protobuf libraries must be downloaded and compiled.

This should be done as follows:

**From within TensorFlow/models/research/**
protoc object_detection/protos/*.proto --python_out=.

# 3.Installation

Install the Tensorflow\models\research\object_detection package by running the following from Tensorflow\models\research:

**From within TensorFlow/models/research/**

pip install .

**To test the installation run:**

Test the installation.
python object_detection/builders/model_builder_tf2_test.py

# 4.Gathering Data

Now that the Tensorflow Object Detection API is ready to go, we need to gather the images needed for training.

To train a robust model, the pictures should be as diverse as possible. So they should have different backgrounds, varying lighting conditions, and unrelated random objects in them.

You can either take pictures yourself, or you can download pictures from the internet.

# 5. Labeling Data

With all the pictures gathered, we come to the next step - labeling the data. Labeling is the process of drawing bounding boxes around the desired objects.

LabelImg is a great tool for creating an object detection data-set.

Download and install LabelImg. Then point it to your images/train and images/test directories, and draw a box around each object in each image

![](https://github.com/sarthakking5/Safety-Gear-Detection/blob/50d8b9ac97380fa5abfccac3877d07eae91fe3fb/images/Screenshot%20(54).png)

# 6. Generating Training data
With the images labeled, we need to create TFRecords that can be served as input data for training the object detector. To create the TFRecords, we will first convert the XML label files created with LabelImg to one CSV file using the xml_to_csv.py script.

python xml_to_csv.py
The above command creates two files in the images directory. One is called test_labels.csv, and another one is called train_labels.csv. Next, we'll convert the CSV files into TFRecords files. For this, open the generate_tfrecord.py file and replace the labelmap inside the class_text_to_int method with your own label map.

Old:

**TO-DO replace this with label map**
def class_text_to_int(row_label):
    if row_label == 'jacket':
        return 1
    elif row_label == 'helmet':
        return 2
    elif row_label == 'glasses':
        return 3
    else:
        return None

Now the TFRecord files can be generated by typing:

python generate_tfrecord.py --csv_input=images/train_labels.csv --image_dir=images/train --output_path=train.record
python generate_tfrecord.py --csv_input=images/test_labels.csv --image_dir=images/test --output_path=test.record

# 7.Getting ready for training
The last thing we need to do before training is to create a label map and a training configuration file.

 Creating a label map
The label map maps an id to a name. We will put it in a folder called training, which is located in the object_detection directory. The labelmap for my detector can be seen below.

item {
    id: 1
    name: 'jacket'
}
item {
    id: 2
    name: 'helmet'
}
item {
    id: 3
    name: 'glasses'
}

The id number of each item should match the id of specified in the generate_tfrecord.py file.

# 8.Training the model

To train the model, execute the following command in the command line:

python train.py --pipeline_config_path=training/ssd_inception_v2_coco.config --mode

# 7. Exporting the inference graph
Now that we have a trained model, we need to generate an inference graph that can be used to run the model.

python /content/models/research/object_detection/exporter_main_v2.py \
    --trained_checkpoint_dir training \
    --output_directory inference_graph \
    --pipeline_config_path training/ssd_inception_v2_coco.config
